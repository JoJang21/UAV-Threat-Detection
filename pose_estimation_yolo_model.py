# -*- coding: utf-8 -*-
"""Pose_Estimation_Yolo_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kf7yY3Eqxp0EszsvVAy_lIN-OcWxEVf0

# Install ultralytics

1.   Download zip folder called 'test_imgs.zip' and place it in /content directory on google colab
2.   Run all below Instructions
"""

!unzip test_imgs.zip

!pip install ultralytics
!pip install ultralytics opencv-python matplotlib
# https://colab.research.google.com/github/cedro3/others/blob/master/VideoPose3D.ipynb for turning 2d yolo points to 3d in a video

"""# Download an Example Image"""

import urllib.request

url = "https://ultralytics.com/images/bus.jpg"  # Image with people
urllib.request.urlretrieve(url, "people.jpg")

"""#  Run YOLOv8 Pose Model"""

from ultralytics import YOLO
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Load the YOLOv8 pose model
model = YOLO("yolov8n-pose.pt")

# Load the image
img = cv2.imread("people.jpg")

# Inference
results = model(img)
res = results[0]

boxes = res.boxes.xyxy.cpu().numpy()
keypoints = res.keypoints.xy.cpu().numpy()
confidences = res.keypoints.conf.cpu().numpy()

# COCO-style keypoint connections
skeleton = [
    (5, 7), (7, 9),       # left arm
    (6, 8), (8, 10),      # right arm
    (11, 13), (13, 15),   # left leg
    (12, 14), (14, 16),   # right leg
    (5, 6),               # shoulders
    (11, 12),             # hips
    (5, 11), (6, 12),     # torso diagonal
    (0, 1), (1, 2), (2, 3), (3, 4),  # head
]

for idx, (box, kp, conf) in enumerate(zip(boxes, keypoints, confidences)):
    x1, y1, x2, y2 = box.astype(int)

    # Label person
    label = f"Person {idx + 1}"
    cv2.putText(img, label, (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

    # Draw keypoints
    for i, (x, y) in enumerate(kp):
        if conf[i] > 0.5:  # draw only confident keypoints
            cv2.circle(img, (int(x), int(y)), 3, (0, 0, 255), -1)

    # Draw skeleton lines
    for i, j in skeleton:
        if conf[i] > 0.5 and conf[j] > 0.5:
            pt1 = tuple(map(int, kp[i]))
            pt2 = tuple(map(int, kp[j]))
            cv2.line(img, pt1, pt2, (255, 0, 0), 2)

# Save and show the result
cv2.imwrite("yolo_pose_skeleton.jpg", img)
cv2_imshow(img)

"""# Find Output"""

# For one image, one result
res = results[0]

# Bounding boxes
boxes = res.boxes.xyxy.cpu().numpy()

# Keypoints (x, y)
keypoints = res.keypoints.xy.cpu().numpy()  # shape: (num_people, 17, 2)

# Confidence for each keypoint
confidences = res.keypoints.conf.cpu().numpy()  # shape: (num_people, 17)

for i, (person_kps, person_conf) in enumerate(zip(keypoints, confidences)):
    print(f"\nüßç Person {i+1}:")
    for j, ((x, y), c) in enumerate(zip(person_kps, person_conf)):
        print(f"  Keypoint {j}: x={x:.1f}, y={y:.1f}, confidence={c:.2f}")

"""# Trying with Man with a gun"""

from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import math
import numpy as np

# Load the YOLOv8 pose model
model = YOLO("yolov8n-pose.pt")

# Run pose detection on both uploaded images
'''
image1_path = "r2na_9.png"
image2_path = "r2ya_10.png"

results1 = model(image1_path)
results2 = model(image2_path)
'''

# Function to visualize result
def show_pose_result(result, title):
    plotted_img = result[0].plot()
    plt.figure(figsize=(6, 8))
    plt.title(title)
    for person in result[0].keypoints.xy:
        keypoints = person.cpu().numpy()
        left_shoulder = keypoints[5]
        x = left_shoulder[0]
        y = left_shoulder[1]
        cv2.circle(plotted_img, (int(x), int(y)), 5, (0, 0, 255), -1) #bgr
        #cv2.circle(plotted_img, (100, 300), 5, (0, 0, 255), -1) #bgr
    plt.imshow(cv2.cvtColor(plotted_img, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()

# Show both images with keypoints
#show_pose_result(results1, "Pose Estimation: Man Pointing Gun")
#show_pose_result(results2, "Pose Estimation: Man Pointing Gun (Front View)")



import os
from PIL import Image

def direction_vector(a, b):
    v = b - a
    return v# / (np.linalg.norm(v) + 1e-6)

#lw_to_nose = direction_vector(left_wrist, nose)

def arm_angle(shoulder, elbow, wrist):
    a = shoulder - elbow
    b = wrist - elbow
    cosine = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-6)
    return np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))

def within_circle(circle_center, point, circle_radius):
    distance = math.sqrt((point[0] - circle_center[0])**2 + (point[1] - circle_center[1])**2)
    return distance < circle_radius

def find_line(px, py, qx, qy):
    if px == qx:
        return None, None  # Vertical line, slope is undefined

    m = (py - qy) / (px - qx)
    b = py - m * px
    return m, b

def find_intersection(m1, b1, m2, b2):
    if m1 == m2:
        return None, None  # Lines are parallel

    x = (b2 - b1) / (m1 - m2)
    y = m1 * x + b1
    return x, y

def iterate_images(folder_path):
    """Iterates through all image files in a folder and prints their paths and sizes.

    Args:
        folder_path: The path to the folder containing the images.
    """
    num_imgs = 0
    all_imgs = []
    for filename in os.listdir(folder_path):
        num_imgs+=1
        all_imgs+=[filename]
    all_imgs.sort(reverse=True)

    for filename in all_imgs:
        if filename.lower().endswith(('.png')):#, '.jpg', '.jpeg', '.gif', '.bmp')):
            image_path = os.path.join(folder_path, filename)
            try:
                img = Image.open(image_path)
                img_name = os.path.basename(image_path)
                print(f"Image: {img_name}, Size: {img.size}")
                #display(img)
                result = model(image_path)
                show_pose_result(result, img_name)

                for person in result[0].keypoints.xy:
                    keypoints = person.cpu().numpy()
                    l_shoulder = keypoints[5]
                    r_shoulder = keypoints[6]
                    l_elbow = keypoints[7]
                    r_elbow = keypoints[8]
                    l_wrist = keypoints[9]
                    r_wrist = keypoints[10]
                    l_eye = keypoints[1]
                    r_eye = keypoints[2]
                    l_ear = keypoints[3]
                    r_ear = keypoints[4]
                    print(f"Left Shoulder: {l_shoulder}")
                    print(f"Right Shoulder: {r_shoulder}")
                    print(f"Left Elbow: {l_elbow}")
                    print(f"Right Elbow: {r_elbow}")
                    print(f"Left Wrist: {l_wrist}")
                    print(f"Right Wrist: {r_wrist}")
                    print(f"Left Eye: {l_eye}")
                    print(f"Right Eye: {r_eye}")
                    print(f"Left Ear: {l_ear}")
                    print(f"Right Ear: {r_ear}")
                    x = l_shoulder[0]
                    y = l_shoulder[1]
                    print("x, y: ", x, " ", y)

                    one_hand = False
                    pistol_hand = "LEFT"
                    l_elbow_exists = (l_elbow[0] != 0 or l_elbow[1] != 0)
                    r_elbow_exists = (r_elbow[0] != 0 or r_elbow[1] != 0)
                    r_wrist_exists = (r_wrist[0] != 0 or r_wrist[1] != 0)
                    l_wrist_exists = (l_wrist[0] != 0 or l_wrist[1] != 0)
                    l_eye_exists = (l_eye[0] != 0 or l_eye[1] != 0)
                    r_eye_exists = (r_eye[0] != 0 or r_eye[1] != 0)
                    l_ear_exists = (l_ear[0] != 0 or l_ear[1] != 0)
                    r_ear_exists = (r_ear[0] != 0 or r_ear[1] != 0)

                    l_arm_exists = l_elbow_exists and l_wrist_exists
                    r_arm_exists = r_elbow_exists and r_wrist_exists

                    l_angle = None
                    r_angle = None
                    if l_arm_exists:
                        l_angle = arm_angle(l_shoulder, l_elbow, l_wrist)
                    else:
                        one_hand = True
                    if r_arm_exists:
                        r_angle = arm_angle(r_shoulder, r_elbow, r_wrist)
                    else:
                        one_hand = True

                    print("l_arm_exists: ", l_arm_exists, " l_angle: ", l_angle)
                    print("r_arm_exists: ", r_arm_exists, " r_angle: ", r_angle)
                    print("pre one_hand: ", one_hand)

                    if img_name[0] == "p": #if detected gun is a pistol
                        print("PISTOL")
                        # Differentiating between 1 hand and 2 hands:  if one arm is obtuse angle (>135), or if arm (wrist and elbow) doesnt exist

                        if (l_arm_exists and not r_arm_exists):
                            one_hand = True
                            pistol_hand = "LEFT"
                        elif (r_arm_exists and not l_arm_exists):
                            one_hand = True
                            pistol_hand = "RIGHT"
                        elif (not l_arm_exists) and (not r_arm_exists):
                            print("THREAT LEVEL 2")
                            continue

                        # below code will work mostly for one hand?????
                        if (l_arm_exists and l_angle > 120):
                            if (r_arm_exists and r_angle > 150):
                                one_hand = False
                                print("THREAT LEVEL 2")
                                #continue
                            elif (r_arm_exists and r_angle < 100):
                                one_hand = True
                                pistol_hand = "RIGHT"
                        if (r_arm_exists and r_angle > 120):
                            if (l_arm_exists and l_angle > 150):
                                one_hand = False
                                print("THREAT LEVEL 2")
                                #continue
                            elif (l_arm_exists and l_angle < 100):
                                one_hand = True
                                pistol_hand = "LEFT"
                        print("post one_hand: ", one_hand)
                        print("pistol_hand: ", pistol_hand)


                        # P, 1 hand, no  aim: wrist is not aligned with shoulder
                        #     wrist is certain distance away from side of eye, the wrist near eye is away from person
                        #     Code: Wrist is near opposite shoulder OR Wrist is "greater than" opposite shoulder, OR wrist is outside of same shoulder (by significant amount)
                        #                            img 8, 5, 4, 1            img 2, 7 (find better imgs)              img 1, 9, 10

                        # P, 1 hand, yes aim: wrist is aligned with shoulder (difficult, get more imgs)
                        #     Code: wrist holding gun is between shoulder and opposite eye?  or midpoint of shoulders?
                        l_mod_wrist = l_wrist[0]
                        if l_arm_exists and l_angle < 10:
                            l_mod_wrist = l_shoulder[0]
                        r_mod_wrist = r_wrist[0]
                        if r_arm_exists and r_angle < 10:
                            r_mod_wrist = r_shoulder[0]
                        if one_hand:
                            if pistol_hand == "LEFT":

                                if within_circle(r_shoulder, l_wrist, 20) or l_mod_wrist < r_shoulder[0] or l_mod_wrist > l_shoulder[0] + 20:
                                    print("THREAT LEVEL 2")
                                    continue
                                elif l_mod_wrist <= l_shoulder[0] or within_circle(l_shoulder, l_wrist, 20) or (r_eye_exists and (l_mod_wrist >= r_eye[0])): #use r_ear?
                                    print("THREAT LEVEL 3") #yes aim
                                    continue
                                else:
                                    print("One Left Hand: Couldn't Determine")
                                    continue
                            elif pistol_hand == "RIGHT":

                                if within_circle(l_shoulder, r_wrist, 20) or r_mod_wrist > l_shoulder[0] or r_mod_wrist < max(r_shoulder[0] - 20, 0):
                                    print("THREAT LEVEL 2")
                                    continue
                                elif r_mod_wrist >=r_shoulder[0] or within_circle(r_shoulder, r_wrist, 20) or (l_eye_exists and (r_mod_wrist <= l_eye[0])): #use l_ear?
                                    print("THREAT LEVEL 3") # yes aim
                                    continue
                                else:
                                    print("One Right Hand: Couldn't Determine")
                                    continue


                        # P, 2 hand, no  aim: one or both wrists (x-val) are outside of shoulders OR
                        #     midpoint of wrists is not within outer eye or ear distance AND the wrist that is outside of the eye/ear distance,
                        #     that wrist is past midpoint of shoulder (x-val)

                        # P, 2 hand, yes aim: midpoint of wrists is between eye or ear distance AND both wrists are between shoulders (x-val),
                        #     measure angle?  (should be acute for both arms)
                        else: # both hands used to hold gun
                            wrist_midpoint = r_mod_wrist + ((l_mod_wrist - r_mod_wrist)//2)
                            leftmost_facial_ftr = max(l_eye[0], l_ear[0])
                            if leftmost_facial_ftr == 0:
                                leftmost_facial_ftr = l_shoulder[0]
                            if (r_ear_exists):
                                rightmost_facial_ftr = r_ear[0]
                            elif (r_eye_exists):
                                rightmost_facial_ftr = r_eye[0]
                            else:
                                rightmost_facial_ftr = r_shoulder[0]

                            if (wrist_midpoint > leftmost_facial_ftr) or (wrist_midpoint < rightmost_facial_ftr):
                                print("THREAT LEVEL 2")
                                continue
                            else:
                                print("THREAT LEVEL 3")
                                continue


                            if l_angle > 120 and r_angle > 120: # ??120?? 110?  90?
                                print("THREAT LEVEL 2")
                            if l_wrist[0] < r_shoulder[0] or r_wrist[0] > l_shoulder[0] or \
                              (r_wrist[0] < max(r_shoulder[0] - 20, 0) and r_angle > 10) or (l_wrist[0] > l_shoulder[0] + 20 and l_angle > 10):
                                print("THREAT LEVEL 2")
                                print("pistol both hands, out of shoulder width")
                                continue
                            print("both hands, nothing decided????????")


                    elif img_name[0] == "r": #if detected gun is a rifle
                        print("RIFLE")
                        # Check if both wrists overlap, if one wrist doesn't exist, check if closer arm's wrist overlaps with opposite shoulder
                        # one or both wrists must be within shoulder
                        # R, 2 hand, no  aim: If both wrists are past the shoulder or if wrists are too far apart (0.6? of shoulders width)

                        # R, 2 hand, yes aim: If wrists are less than 0.6 shoulder apart
                        #    (both wrists converge to certain shoulder, both wrists are near the circle?)
                        #     Compare angles created by shoulder-elbow and elbow-wrist.  Use arm with greater angle.
                        #     if line created by wrist-elbow and shoulders intersect near shoulder, then good.
                        #  if angle created by other arm is very small (less than 30 degrees) (means wrist is close to shoulder)
                        wrists_width = np.linalg.norm(np.abs(l_wrist - r_wrist))
                        shoulders_width = np.linalg.norm(np.abs(l_shoulder - r_shoulder))
                        print("wrists_width: ", wrists_width)
                        print("shoulders_width: ", shoulders_width)
                        if wrists_width > 0.7 * shoulders_width:
                            print("THREAT LEVEL 2, r1")
                            continue
                        if (l_wrist[0] < r_shoulder[0] and r_wrist[0] < max(r_shoulder[0] - 10, 0)) or (r_wrist[0] > l_shoulder[0] and l_wrist[0] > l_shoulder[0] + 10):
                            print("THREAT LEVEL 2, r2") # both wrists are away from shoulder,  -20? -15?
                            # check arm angle?????
                            continue
                        if (l_wrist[0] > l_shoulder[0] + 0.4*shoulders_width) or (r_wrist[0] < max(r_shoulder[0] - 0.4*shoulders_width, 0)): #0.5? 0.6?
                            print("THREAT LEVEL 2, r3") # both wrists are away from shoulder
                            # check arm angle?????
                            continue


                        print("Testing for threat level 3")
                        l_mod_wrist = l_wrist[0]
                        if l_arm_exists and r_arm_exists:
                            if l_angle > r_angle:
                                support_arm = "LEFT"
                            elif l_angle < r_angle:
                                support_arm = "RIGHT"

                        r_mod_wrist = r_wrist[0]
                        if l_arm_exists and l_angle < 15:
                            l_mod_wrist = l_shoulder[0]
                        r_mod_wrist = r_wrist[0]
                        if r_arm_exists and r_angle < 15:
                            r_mod_wrist = r_shoulder[0]
                        shoulder_m, shoulder_b = find_line(l_shoulder[0], -l_shoulder[1], r_shoulder[0], -r_shoulder[1])
                        # print("shoulder_m", shoulder_m, " shoulder_b: ", shoulder_b)
                        if support_arm == "LEFT":
                            support_m, support_b = find_line(l_elbow[0], -l_elbow[1], l_wrist[0], -l_wrist[1])
                        elif support_arm == "RIGHT":
                            support_m, support_b = find_line(r_elbow[0], -r_elbow[1], r_wrist[0], -r_wrist[1])
                        # print("support_m: ", support_m, " support_b: ", support_b)
                        if shoulder_b is not None and support_b is not None:
                            x, y = find_intersection(shoulder_m, shoulder_b, support_m, support_b)
                            x = abs(x)
                            y = abs(y)
                            # print("intersection: ", x, " ", y)
                            if x is not None and y is not None:
                                if support_arm == "LEFT" and within_circle(r_shoulder, (x, y), 0.33 * shoulders_width) or \
                                   support_arm == "RIGHT" and within_circle(l_shoulder, (x, y), 0.33 * shoulders_width):  #0.2?, 0.1?
                                    print("THREAT LEVEL 3")
                                    continue
                                elif (support_arm == "LEFT" and within_circle(r_shoulder, (x, y), 0.5 * shoulders_width) \
                                      and l_angle >= 30 and l_angle <= 70) or \
                                     (support_arm == "RIGHT" and within_circle(l_shoulder, (x, y), 0.5 * shoulders_width) \
                                      and r_angle >= 30 and r_angle <= 70):  #0.2?, 0.1?
                                    print("THREAT LEVEL 3")
                                    continue
                                else:
                                    print("THREAT LEVEL 2")
                                    continue

                img.close()
            except Exception as e:
                print(f"Error opening {image_path}: {e}")


# Example usage:
folder_path = "test_imgs/"
iterate_images(folder_path)




'''

OBJ_DETECTION AND POSE_ESTIMATE INTEGRATION
-Input:  screen record and send video to our model.  Let model process video using OpenCV to get
individual image frames
-Object detection output:  Calculate overlap of gun and human bounding boxes.  Then output Threat
leve1 0, 1, or 2, WITH Bounding boxes that are labeled with gun type (list data structure?).
    -for each human identified, if theres a gun overlap (threat level 2), make
    threat_list = [(human1_bbox, threat_level, gun1_bbox,  gun1_type)]
-Integration of object detection and pose estimation, output:  crop images and increase or
decrease image size.  Then output Threat leve1 2 or 3, WITH Bounding boxes.

--Also have to adjust picture size depending on how far or close individual is

'''

from ultralytics import YOLO
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load model
model = YOLO('yolov8x-pose.pt')  # or yolov8n-pose.pt for lightweight

# Load image
img_path = "man-pointing-with-gun.jpg"
image = cv2.imread(img_path)

img_path2 = "man-poinging-with-his-machine-gun.jpg"
image2 = cv2.imread(img_path2)

# Predict
results = model.predict(image, save=False)

results2 = model.predict(image2, save=False)

# COCO skeleton
skeleton = [
    (0, 1), (0, 2), (1, 3), (2, 4),
    (5, 6), (5, 7), (6, 8), (7, 9), (8, 10),
    (5, 11), (6, 12), (11, 12), (11, 13), (13, 15),
    (12, 14), (14, 16)
]

# üö® Improved Threat Detection Logic
def is_threatening_pose_directional(keypoints):
    nose = keypoints[0]
    left_shoulder = keypoints[5]
    right_shoulder = keypoints[6]
    left_elbow = keypoints[7]
    right_elbow = keypoints[8]
    left_wrist = keypoints[9]
    right_wrist = keypoints[10]

    def direction_vector(a, b):
        v = b - a
        return v / (np.linalg.norm(v) + 1e-6)

    lw_to_nose = direction_vector(left_wrist, nose)
    rw_to_nose = direction_vector(right_wrist, nose)
    le_to_lw = direction_vector(left_elbow, left_wrist)
    re_to_rw = direction_vector(right_elbow, right_wrist)

    left_dot = np.dot(lw_to_nose, le_to_lw)
    right_dot = np.dot(rw_to_nose, re_to_rw)

    def arm_angle(shoulder, elbow, wrist):
        a = shoulder - elbow
        b = wrist - elbow
        cosine = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-6)
        return np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))

    left_angle = arm_angle(left_shoulder, left_elbow, left_wrist)
    right_angle = arm_angle(right_shoulder, right_elbow, right_wrist)

    left_threat = left_angle >= 160 and left_dot >= 0.7
    right_threat = right_angle >= 160 and right_dot >= 0.7

    main_threat = left_threat or right_threat

    # Backup rule
    wrist_dist = np.linalg.norm(left_wrist - right_wrist)
    horizontal_distance = abs(left_wrist[0] - right_wrist[0])
    vertical_offset_from_nose = max(abs(left_wrist[1] - nose[1]), abs(right_wrist[1] - nose[1]))

    backup_threat = (
        wrist_dist < 500 and
        horizontal_distance < 350 and
        vertical_offset_from_nose < 1000
    )

    return main_threat or backup_threat

# Draw keypoints, skeleton, and label
for person in results[0].keypoints.xy:
    keypoints = person.cpu().numpy()

    # Draw keypoints
    for i, (x, y) in enumerate(keypoints):
        color = (0, 255, 255)  # Default yellow
        if i in [5, 6]: color = (0, 255, 0)     # shoulders
        if i in [7, 8]: color = (0, 0, 255)     # elbows
        if i in [9, 10]: color = (255, 0, 0)    # wrists
        cv2.circle(image, (int(x), int(y)), 10, color, -1)
        cv2.putText(image, str(i), (int(x)+5, int(y)-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    # Draw skeleton
    for i, j in skeleton:
        pt1 = tuple(np.round(keypoints[i]).astype(int))
        pt2 = tuple(np.round(keypoints[j]).astype(int))
        cv2.line(image, pt1, pt2, (255, 255, 255), 3)

    # Threat label
    label = "THREAT" if is_threatening_pose_directional(keypoints) else "NO THREAT"
    label_color = (0, 0, 255) if label == "THREAT" else (0, 255, 0)
    x_text, y_text = int(keypoints[0][0]), int(keypoints[0][1])
    label_y = max(50, int(y_text) - 500)  # shift upward but not off-screen
    cv2.putText(image, label, (x_text, label_y),
            cv2.FONT_HERSHEY_DUPLEX, 2.5, label_color, 5)

# Draw keypoints, skeleton, and label
for person in results2[0].keypoints.xy:
    keypoints = person.cpu().numpy()

    # Draw keypoints
    for i, (x, y) in enumerate(keypoints):
        color = (0, 255, 255)  # Default yellow
        if i in [5, 6]: color = (0, 255, 0)     # shoulders
        if i in [7, 8]: color = (0, 0, 255)     # elbows
        if i in [9, 10]: color = (255, 0, 0)    # wrists
        cv2.circle(image2, (int(x), int(y)), 10, color, -1)
        cv2.putText(image2, str(i), (int(x)+5, int(y)-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    # Draw skeleton
    for i, j in skeleton:
        pt1 = tuple(np.round(keypoints[i]).astype(int))
        pt2 = tuple(np.round(keypoints[j]).astype(int))
        cv2.line(image2, pt1, pt2, (255, 255, 255), 3)

    # Threat label
    label = "THREAT" if is_threatening_pose_directional(keypoints) else "NO THREAT"
    label_color = (0, 0, 255) if label == "THREAT" else (0, 255, 0)
    x_text, y_text = int(keypoints[0][0]), int(keypoints[0][1])
    label_y = max(50, int(y_text) - 500)  # shift upward but not off-screen
    cv2.putText(image2, label, (x_text, label_y),
            cv2.FONT_HERSHEY_DUPLEX, 2.5, label_color, 5)


# Convert to RGB and show
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.figure(figsize=(14, 10))
plt.imshow(image_rgb)
plt.title("YOLOv8 Pose + Threat Detection", fontsize=20)
plt.axis('off')
plt.show()

image2_rgb = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)
plt.figure(figsize=(14, 10))
plt.imshow(image2_rgb)
plt.title("YOLOv8 Pose + Threat Detection", fontsize=20)
plt.axis('off')
plt.show()